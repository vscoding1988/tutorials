# Url Shortener

## Concept

This is a simple URL shortener service that allows users to shorten long URLs to a more manageable length. The service
will generate a unique short URL for each long URL provided by the user. The short URL can then be used to redirect
users to the original target URL. A short URL consists of the domain (not to be confused with the URL domain) and the
short url segment: `http://localhost:8080/{shortUrlDomain}/{shortUrlSegment}`.

- The short url domain, is the ID of the Team that created the short URL. This allows for multiple teams to use the
  service without conflicting with each other. It is also can be used for campaign tracking, since the referer tracking
  is based on the short url domain (see statistics concept).
- The short url segment is a unique identifier (inside it's domain) for the short URL. It is generated by the service
  and is unique for each long URL.

## Statistics Concept

When a user accesses a short URL, the service will redirect the user to the original target URL. Before redirecting the
user, the service will log the request in the database. The log will contain the following information:

- The referer URL (the URL that the user was on before accessing the short URL).
- Increase the number of visits for the short URL by one.

This will lead to a very big (at some point unmanageable) database, so there a merge process that will run every 24
hours (see `StatisticsMerger.java`) the merge will create a summary of the statistics for each short URL. Based on
following rules:

- Merge last week data to 15 Minutes chunks.
- Merge last month to 1 Hour chunks.
- Merge last year to one day chunks.
- Merge older data one entry.

This generates under full load:

- 4 * 24 * 7 = 672 entries for first week per URL
- (30 -7) * 24 = 552 entries for first month per URL
- (365 - 30) = 335 entries for first year per URL
- Everything older than a year is merged to one entry per URL.

So we have 672 + 552 + 335 + 1 = 1560 entries per URL

This is a lot of data, but it also is considering, that every url is used at least every 15 minutes, also the data
for the current day is not merged, so the actual number of entries is higher. But the bigger problem is the referer
value, if we try to include referer values in the merging, this will make the database explode. There are a couple of
ways around it:

- Do not keep referer values older than a week (or a month), I do believe this has to be done anyway
- use separate database or SOLR for statistics and the referer values (entirely, or just for the newer data)

For the scope of the project, we will persist the referer values based on short url domain. This is a compromise between
data size and data quality. This will give sufficient information about the user behavior, but will not lead (hopefully) 
to exploding the databases.

> **Note:** It is probably a better idea to disable the merger and do the merging with SQL scripts, making sure the is
> kept in a way that is most suitable for the actual use case. To disable the merger start the app with the profile `disable-merger`
